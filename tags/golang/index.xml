<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Golang on Interview Questions for Machine Learning</title>
    <link>https://joewellhe.github.io/tags/golang/</link>
    <description>Recent content in Golang on Interview Questions for Machine Learning</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018. All rights reserved.</copyright>
    <lastBuildDate>Wed, 28 Mar 2018 19:18:23 +0800</lastBuildDate>
    
	<atom:link href="https://joewellhe.github.io/tags/golang/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>线性模型</title>
      <link>https://joewellhe.github.io/post/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Wed, 28 Mar 2018 19:18:23 +0800</pubDate>
      
      <guid>https://joewellhe.github.io/post/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</guid>
      <description>线性回归 模型：
策略：普通最小二乘（OLS）
优化方式：
 梯度下降   正规方差  优点：实现简单，计算简单，有解析解；
缺点：不能拟合非线性数据；
Q1: （普通最小二乘）OLS是用于线性回归, （最大似然）MLE是用于逻辑回归，解释以上描述？ 简单地说，普通最小二乘法（OLS）是在线性回归中求解参数使用的方法，可以通过解正规方程得到解析解。 此外还可以通过梯度下降的方法求解最小均方误差的数值解，且普通最小二乘由梯度下降求解可以收敛到全局的最优解。 最大似然估计是一种常用的参数估计方式，最大似然性有助于选择使参数最可能产生观测数据的可能性最大化的参数值。 LR模型中通过最大化对数似然函数得到最优解。
事实上，线性回归的OLS在满足一定的数据分布假设的情况下，和MLE是等同的。
我们假设线性回归产生的误差是服从正态分布的，即
则根据正态分布的平移收缩，我们可以知道y也满足如下的正态分布
通过最大化对数似然函数我们可以得到
可以看到，减号前为常数项，最大化对数似然函数等价于普通最小二乘。
Q2: 关于MLE（最大似然估计），下面哪一项或几项说法是正确的 A. MLE可能不存在
B. MLE总是存在
C. 如果MLE存在，可能不是唯一的
D. 如果MLE存在，肯定是唯一的
A. 1 and 4 B. 2 and 3 C. 1 and 3 D. 2 and 4
答案：C
MLE是通过似然函数导数等于0来找最优点，即找驻点所以有以下结论： MLE可以不是转折点，即，可以不是似然（和对数似然）函数的一阶导数的消失点。 MLE可以不是唯一的。
Q3: 在推导线性回归参数时，我们会做出以下哪些假设？ 因变量y和预测变量x之间的真实关系是线性的。
模型的误差在统计意义上是独立的。
误差通常分布是均值为0，且标准差为常数。
预测变量x是非随机的，而且不存在测量误差。
A.1,2,3
B.1,3,4
C1,3
D. 以上所有
答案：D
当我们推到回归参数的时候，我们会提出以上四项假设。。当任意一项假设不成立的时候，得到的模型将会是错误的。
Q4:假设我们已经由3次多项式回归生成了数据（三次正好能拟合改组数据）。现在请考虑以下几种说法，并选择合适项。 简单线性回归将具有高偏差和低方差</description>
    </item>
    
  </channel>
</rss>